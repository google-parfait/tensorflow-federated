{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqjnBbmi8BPM"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PTdfUcwp8Eru"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grBmytrShbUE"
      },
      "source": [
        "# High-Performance Simulation with Kubernetes\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This tutorial will describe how to set up high-performance simulation using a TFF runtime deployed on Kubernetes.\n",
        "\n",
        "For demonstrative purposes, we'll use the TFF simulation for image classification from the tutorial, [Federated Learning for Image Classification](https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification), but we'll run it against a multi-machine setup consisting of two TFF workers running in Kubernetes. We'll use the same [EMNIST dataset](https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#preparing_the_input_data) for training, but split into two partitions, one for each TFF worker.\n",
        "\n",
        "This tutorial refers to the following Google Cloud services,\n",
        "* [GKE](https://cloud.google.com/kubernetes-engine/) to create the Kubernetes cluster, but all the steps after the cluster is created can be used with any Kubernetes installation.\n",
        "* [Filestore](https://cloud.google.com/filestore) to serve the training data, but works with any storage medium that can be mounted as a Kubernetes [persistent volume](https://kubernetes.io/docs/concepts/storage/persistent-volumes/).\n",
        "\n",
        "\u003e **Note:** This tutorial assumes you have an existing GCP project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyXVaj0dknQw"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/high_performance_simulation_with_kubernetes\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/federated/blob/v0.41.0/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/federated/blob/v0.41.0/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://storage.googleapis.com/tensorflow_docs/federated/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003eDownload notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiq_MY4LopET"
      },
      "source": [
        "## Launch the TFF Workers on Kubernetes\n",
        "\n",
        "### Package TFF Worker Binary\n",
        "\n",
        "[worker_service.py](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/worker_service.py) contains the source code for our custom TFF worker. It runs a simulation server with custom logic for loading a dataset partition and sampling from it for each round of federated learning. (To learn more, see [Loading Remote Data in TFF](https://www.tensorflow.org/federated/tutorials/loading_remote_data).)\n",
        "\n",
        "We're going to deploy our TFF worker as a containerized application on Kubernetes. Lets start by building a Docker image. Using this [Dockerfile](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/Dockerfile), we can package the code by running,\n",
        "\n",
        "```\n",
        "$ WORKER_IMAGE=tff-worker-service:latest\n",
        "\n",
        "$ docker build --tag $WORKER_IMAGE --file \"./Dockerfile\" .\n",
        "```\n",
        "\n",
        "(Assuming [worker_service.py](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/worker_service.py) and [Dockerfile](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/Dockerfile) are located in your working directory.)\n",
        "\n",
        "Then publish the image to a container repository where it can be accessed by the Kubernetes cluster we're about to create, e.g., \n",
        "\n",
        "```\n",
        "$ docker push $WORKER_IMAGE\n",
        "```\n",
        "\n",
        "### Create a Kubernetes Cluster\n",
        "\n",
        "The following step only needs to be done once. The cluster can be re-used for future workloads.\n",
        "\n",
        "Follow the GKE instructions to [create a cluster](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver#enabling_the_on_a_new_cluster) with Filestore CSI driver enabled, e.g.,\n",
        "\n",
        "```\n",
        "gcloud container clusters create tff-cluster --addons=GcpFilestoreCsiDriver\n",
        "```\n",
        "\n",
        "The commands to interact with GCP can be run [locally](https://cloud.google.com/kubernetes-engine/docs/tutorials/hello-app#option_b_use_command-line_tools_locally) or in the [Google Cloud Shell](https://cloud.google.com/shell/). We recommend the Google Cloud Shell since it doesn't require additional setup.\n",
        "\n",
        "The rest of this tutorial assumes that the cluster is named `tff-cluster`, but the actual name isn't important.\n",
        "\n",
        "### Deploy the TFF Worker Application\n",
        "\n",
        "[worker_deployment.yaml](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/worker_deployment.yaml) declares the configuration for standing up two TFF workers, each in their own Kubernetes pod with two replicas each. We can apply this configuration to our running cluster,   \n",
        "\n",
        "```\n",
        "kubectl apply -f worker_deployment.yaml\n",
        "```\n",
        "\n",
        "Once the changes have been requested, you can check the pods are ready,\n",
        "\n",
        "```\n",
        "kubectl get pod\n",
        "NAME                                        READY   STATUS    RESTARTS   AGE\n",
        "tff-workers-deployment-1-6bb8d458d5-hjl9d   1/1     Running   0          5m\n",
        "tff-workers-deployment-1-6bb8d458d5-jgt4b   1/1     Running   0          5m\n",
        "tff-workers-deployment-2-6cb76c6f5d-hqt88   1/1     Running   0          5m\n",
        "tff-workers-deployment-2-6cb76c6f5d-xk92h   1/1     Running   0          5m\n",
        "```\n",
        "\n",
        "Each worker instance runs behind a load balancer with an endpoint. Look up the external IP address of the load balancers,\n",
        "\n",
        "```\n",
        "kubectl get service\n",
        "NAME                    TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)        AGE\n",
        "tff-workers-service-1   LoadBalancer   XX.XX.X.XXX   XX.XXX.XX.XXX   80:31830/TCP   6m\n",
        "tff-workers-service-2   LoadBalancer   XX.XX.X.XXX   XX.XXX.XX.XXX   80:31319/TCP   6m\n",
        "```\n",
        "\n",
        "You'll need it later to connect the training loop to the running workers.\n",
        "\n",
        "\u003e **Note:** This exposes your deployment to the internet and is for demo\n",
        "purposes only. For production use, a firewall and authentication are strongly\n",
        "recommended."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyq4xsa6BJ3Q"
      },
      "source": [
        "## Prepare Training Data\n",
        "\n",
        "\n",
        "The EMNIST partitions we'll consume for training can be downloaded from TFF's public [dataset repository](https://console.cloud.google.com/storage/browser/tff-datasets-public/emnist-partitions/2-partition), \n",
        "\n",
        "```\n",
        "gsutil cp -r gs://tff-datasets-public/emnist-partitions/2-partition\n",
        "```\n",
        "\n",
        "You can then upload them to each pod by copying them to a replica, e.g.,\n",
        "\n",
        "```\n",
        "kubectl cp emnist_part_1.sqlite tff-workers-deployment-1-6bb8d458d5-hjl9d:/root/worker/data/emnist_partition.sqlite\n",
        "\n",
        "kubectl cp emnist_part_2.sqlite tff-workers-deployment-2-6cb76c6f5d-hqt88:/root/worker/data/emnist_partition.sqlite\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zFenI3IPpgI"
      },
      "source": [
        "## Run Simulation\n",
        "\n",
        "Now we're ready to run simulations against our cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-q80uOHl4dg"
      },
      "source": [
        "### Setup TFF Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke7EyuvG0Zyn"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFkcJZAojZDm"
      },
      "source": [
        "### Define the Training Procedure\n",
        "\n",
        "The following defines the dataset iteration methodology, the model architecture, and the round-over-round process for federated learning. (For more [detail](https://www.tensorflow.org/federated/tutorials/loading_remote_data#training_the_model).)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0Qk0sCDZUQR"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from typing import Any, Optional, List\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "\n",
        "class FederatedData(tff.program.FederatedDataSource,\n",
        "                    tff.program.FederatedDataSourceIterator):\n",
        "  \"\"\"Interface for interacting with the federated training data.\"\"\"\n",
        "\n",
        "  def __init__(self, type_spec: tff.FederatedType):\n",
        "    self._type_spec = type_spec\n",
        "    self._capabilities = [tff.program.Capability.RANDOM_UNIFORM]\n",
        "\n",
        "  @property\n",
        "  def federated_type(self) -\u003e tff.FederatedType:\n",
        "    return self._type_spec\n",
        "\n",
        "  @property\n",
        "  def capabilities(self) -\u003e List[tff.program.Capability]:\n",
        "    return self._capabilities\n",
        "\n",
        "  def iterator(self) -\u003e tff.program.FederatedDataSourceIterator:\n",
        "    return self\n",
        "\n",
        "  def select(self, num_clients: Optional[int] = None) -\u003e Any:\n",
        "    data_uris = [f'uri://{i}' for i in range(num_clients)]\n",
        "    return tff.framework.CreateDataDescriptor(\n",
        "        arg_uris=data_uris, arg_type=self._type_spec)\n",
        "\n",
        "\n",
        "input_spec = collections.OrderedDict([\n",
        "    ('x', tf.TensorSpec(shape=(1, 784), dtype=tf.float32, name=None)),\n",
        "    ('y', tf.TensorSpec(shape=(1, 1), dtype=tf.int32, name=None))\n",
        "])\n",
        "element_type = tff.types.StructWithPythonType(\n",
        "    input_spec, container_type=collections.OrderedDict)\n",
        "dataset_type = tff.types.SequenceType(element_type)\n",
        "\n",
        "train_data_source = FederatedData(type_spec=dataset_type)\n",
        "train_data_iterator = train_data_source.iterator()\n",
        "\n",
        "def model_fn():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(units=10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "  return tff.learning.from_keras_model(\n",
        "      model,\n",
        "      input_spec=input_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "\n",
        "trainer = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "\n",
        "\n",
        "def train_loop(num_rounds=10, num_clients=10):\n",
        "  state = trainer.initialize()\n",
        "  for round in range(1, num_rounds + 1):\n",
        "    train_data = train_data_iterator.select(num_clients)\n",
        "    result = trainer.next(state, train_data)\n",
        "    state = result.state\n",
        "    train_metrics = result.metrics['client_work']['train']\n",
        "    print('round {:2d}, metrics={}'.format(round, train_metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5OhgAp7jrNI"
      },
      "source": [
        "### Connect to TFF Workers\n",
        "\n",
        "By default, TFF executes all computations locally. In this step we tell TFF to connect to the Kubernetes services we set up above. Be sure to copy the external IP addresses of your services here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXSLXwcdciYm"
      },
      "outputs": [],
      "source": [
        "import grpc\n",
        "\n",
        "ip_address_1 = '0.0.0.0'  #@param {type:\"string\"}\n",
        "ip_address_2 = '0.0.0.0'  #@param {type:\"string\"}\n",
        "port = 80\n",
        "\n",
        "channels = [\n",
        "    grpc.insecure_channel(f'{ip_address_1}:{port}'),\n",
        "    grpc.insecure_channel(f'{ip_address_2}:{port}')\n",
        "]\n",
        "\n",
        "tff.backends.native.set_remote_python_execution_context(channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEgpmgSRktJY"
      },
      "source": [
        "### Execute Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw92IA6_Zrud"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  1, metrics=OrderedDict([('sparse_categorical_accuracy', 0.10557769), ('loss', 12.475689), ('num_examples', 5020), ('num_batches', 5020)])\n",
            "round  2, metrics=OrderedDict([('sparse_categorical_accuracy', 0.11940298), ('loss', 10.497084), ('num_examples', 5360), ('num_batches', 5360)])\n",
            "round  3, metrics=OrderedDict([('sparse_categorical_accuracy', 0.16223507), ('loss', 7.569645), ('num_examples', 5190), ('num_batches', 5190)])\n",
            "round  4, metrics=OrderedDict([('sparse_categorical_accuracy', 0.2648384), ('loss', 6.0947175), ('num_examples', 5105), ('num_batches', 5105)])\n",
            "round  5, metrics=OrderedDict([('sparse_categorical_accuracy', 0.29003084), ('loss', 6.2815433), ('num_examples', 4865), ('num_batches', 4865)])\n",
            "round  6, metrics=OrderedDict([('sparse_categorical_accuracy', 0.40237388), ('loss', 4.630901), ('num_examples', 5055), ('num_batches', 5055)])\n",
            "round  7, metrics=OrderedDict([('sparse_categorical_accuracy', 0.4288425), ('loss', 4.2358975), ('num_examples', 5270), ('num_batches', 5270)])\n",
            "round  8, metrics=OrderedDict([('sparse_categorical_accuracy', 0.46349892), ('loss', 4.3829923), ('num_examples', 4630), ('num_batches', 4630)])\n",
            "round  9, metrics=OrderedDict([('sparse_categorical_accuracy', 0.492094), ('loss', 3.8121278), ('num_examples', 4680), ('num_batches', 4680)])\n",
            "round 10, metrics=OrderedDict([('sparse_categorical_accuracy', 0.5872674), ('loss', 3.058461), ('num_examples', 5105), ('num_batches', 5105)])\n"
          ]
        }
      ],
      "source": [
        "train_loop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "high_performance_simulation_with_kubernetes.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
