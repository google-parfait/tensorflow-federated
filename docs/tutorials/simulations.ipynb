{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "grBmytrShbUE"
      },
      "source": [
        "# High-performance simulations with TFF\n",
        "\n",
        "This tutorial will describe how to setup high-performance simulations with TFF\n",
        "in a variety of common scenarios.\n",
        "\n",
        "NOTE: The mechanisms covered here are not included in the latest release, have\n",
        "not been tested yet, and the API may evolve. In order to follow this tutorial,\n",
        "you will need to build a TFF pip package from scratch from the latest sources, and install it in a Jupyter notebook with a Python 3 runtime. The new executor\n",
        "stack is not compatible with Python 2.\n",
        "\n",
        "TODO(b/134543154): Populate the content, some of the things to cover here:\n",
        "- using GPUs in a single-machine setup,\n",
        "- multi-machine setup on GCP/GKE, with and without TPUs,\n",
        "- interfacing MapReduce-like backends,\n",
        "- current limitations and when/how they will be relaxed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yiq_MY4LopET"
      },
      "source": [
        "## Before we begin\n",
        "\n",
        "First, make sure your notebook is connected to a backend that has the relevant\n",
        "components (including gRPC dependencies for multi-machine scenarios) compiled.\n",
        "\n",
        "Now, if you are running this notebook in Jupyter, you may need to take an extra\n",
        "step to work around the\n",
        "[limitations of Jypter with asyncio](https://github.com/jupyter/notebook/issues/3397#issuecomment-419386811)\n",
        "by installing the [nest_asyncio](https://github.com/erdewit/nest_asyncio)\n",
        "package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tnngjncsPq15"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_zFenI3IPpgI"
      },
      "source": [
        "Now, let's start by loading the MNIST example from the TFF website, and\n",
        "declaring the Python function that will run a small experiment loop. In order\n",
        "to use all data and make sure there is enough work for each round, we partition\n",
        "data from all users into 10 groups and assign one group per simulated client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ke7EyuvG0Zyn"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_federated\n",
        "!pip install tf-nightly==1.15.0.dev20190805"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2dVPgxN0MdG2"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "import tensorflow_federated as tff\n",
        "from tff.examples import mnist\n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 100\n",
        "NUM_CLIENTS = 10\n",
        "\n",
        "source, _ = tff.simulation.datasets.emnist.load_data()\n",
        "\n",
        "def client_data(n):\n",
        "  ids_per_client = int(len(source.client_ids) / NUM_CLIENTS)\n",
        "  start = ids_per_client * n\n",
        "  limit = ids_per_client * (n + 1)\n",
        "  combined_dataset = None\n",
        "  while start \u003c limit:\n",
        "    dataset = mnist.keras_dataset_from_emnist(\n",
        "        source.create_tf_dataset_for_client(source.client_ids[start]))\n",
        "    start = start + 1\n",
        "    if combined_dataset is not None:\n",
        "      combined_dataset = combined_dataset.concatenate(dataset)\n",
        "    else:\n",
        "      combined_dataset = dataset\n",
        "  return combined_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
        "\n",
        "train_data = [client_data(n) for n in range(NUM_CLIENTS)]\n",
        "\n",
        "batch = tf.nest.map_structure(lambda x: x.numpy(), iter(train_data[0]).next())\n",
        "\n",
        "def model_fn():\n",
        "  return tff.learning.from_compiled_keras_model(\n",
        "      mnist.create_simple_keras_model(), batch)\n",
        "\n",
        "trainer = tff.learning.build_federated_averaging_process(model_fn)\n",
        "\n",
        "def evaluate(num_rounds=10):\n",
        "  state = trainer.initialize()\n",
        "  for _ in range(num_rounds):\n",
        "    t1 = time.time()\n",
        "    state, metrics = trainer.next(state, train_data)\n",
        "    t2 = time.time()\n",
        "    print('loss {}, round time {}'.format(metrics.loss, t2 - t1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CDHJF7EIiEy-"
      },
      "source": [
        "## Single-machine simulations\n",
        "\n",
        "A simple local multi-threaded executor can be created using a new currently\n",
        "undocumented framework function `tff.framework.create_local_executor()`, and\n",
        "made default by calling `tff.framework.set_default_executor()`, as follows.\n",
        "Note that the elocal executor currently requires the number of clients to be\n",
        "specified at setup time. We'll relax this restriction in the near future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "height": 185
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 148939,
          "status": "ok",
          "timestamp": 1565148149221,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "-V6uCS_BMoR9",
        "outputId": "98124893-44c4-4bf5-f44f-3cc5abfc149e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss 3.55805, round time 15.59630298614502\n",
            "loss 1.20457, round time 14.756427764892578\n",
            "loss 0.968885, round time 14.836261749267578\n",
            "loss 0.876231, round time 15.162195682525635\n",
            "loss 0.822056, round time 14.794559955596924\n",
            "loss 0.782698, round time 14.633676767349243\n",
            "loss 0.754549, round time 14.806968688964844\n",
            "loss 0.735254, round time 14.6411874294281\n",
            "loss 0.718297, round time 14.8141508102417\n",
            "loss 0.703123, round time 14.478189468383789\n"
          ]
        }
      ],
      "source": [
        "tff.framework.set_default_executor(\n",
        "    tff.framework.create_local_executor(num_clients=NUM_CLIENTS))\n",
        "\n",
        "evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6NnVUd6qM6h-"
      },
      "source": [
        "Now, for comparison, let's run the same training code using the reference\n",
        "executor. The reference executor can be automatically installed back by calling\n",
        "the `tff.framework.set_default_executor()` function without an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "height": 185
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 2754895,
          "status": "ok",
          "timestamp": 1565150976313,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "ThVuHtUVM9LK",
        "outputId": "86e02712-f1eb-414a-f981-4d2f9e3babed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss 3.55805, round time 273.98993945121765\n",
            "loss 1.20457, round time 275.3648579120636\n",
            "loss 0.968885, round time 275.70571970939636\n",
            "loss 0.876231, round time 276.54428720474243\n",
            "loss 0.822056, round time 277.55314350128174\n",
            "loss 0.782698, round time 273.0547134876251\n",
            "loss 0.754549, round time 276.6848702430725\n",
            "loss 0.735254, round time 277.1024343967438\n",
            "loss 0.718297, round time 273.02305459976196\n",
            "loss 0.703123, round time 275.2886736392975\n"
          ]
        }
      ],
      "source": [
        "tff.framework.set_default_executor()\n",
        "\n",
        "evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bZ171NhcNa3M"
      },
      "source": [
        "## Multi-machine simulations on GCP/GKE, GPUs, TPUs, and beyond...\n",
        "\n",
        "Coming very soon."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "High-performance simulations with TFF",
      "provenance": [
        {
          "file_id": "14vSn6H8hu35BMb48b48hHYJ3Lln3OTQL",
          "timestamp": 1561680139142
        }
      ],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
