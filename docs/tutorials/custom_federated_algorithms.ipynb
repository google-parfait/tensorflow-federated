{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "32xflLc4NTx-"
      },
      "source": [
        "# Custom Federated Algorithms with the Federated Core API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_igJ2sfaNWS8"
      },
      "source": [
        "In this tutorial, we introduce the Federated Core (FC), a set of lower-level\n",
        "interfaces that can be used to implement custom types of federated algorithms,\n",
        "and we show how one can implement a simplified version of federated training and\n",
        "evaluation in terms of these lower-level interfaces.\n",
        "\n",
        "The tutorial is designed to be self-contained, but it builds concepts\n",
        "systematically in a bottom-up fashion, and somewhat in-depth. We encourage the\n",
        "reader to first skim over\n",
        "[Federated Learning for Image Classification](federated_learning_for_image_classification.md)\n",
        "for a higher-level and more gentle introduction to the TensorFlow Federated\n",
        "framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cuJuLEh2TfZG"
      },
      "source": [
        "## Before we start\n",
        "\n",
        "Before we start, try to run the following \"Hello World\" example to make sure\n",
        "your environment is correctly setup. If it doesn't work, please refer to the\n",
        "[Installation](../install.md) guide for instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 13085,
          "status": "ok",
          "timestamp": 1549990657175,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "-skNC6aovM46",
        "outputId": "d71f26cf-f846-4e2a-f5c4-8e4258ebdf92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow_federated import python as tff\n",
        "\n",
        "tf.enable_resource_variables()\n",
        "\n",
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "\n",
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9xX97PJwaBLf"
      },
      "source": [
        "## Federated data\n",
        "\n",
        "One of the distinguishing features of TFF is that it allows you to compactly\n",
        "express TensorFlow-based computations on *federated data*. We will be using the\n",
        "term *federated data* in this tutorial to refer to a collection of data items\n",
        "hosted across a group of devices in a distributed system. For example, applications\n",
        "running on mobile devices may collect data and store it locally, without uploading \n",
        "to a centralized location. Or, an array of distributed sensors may collect and store \n",
        "temperature readings at their locations.\n",
        "\n",
        "Federated data like those in the above examples are treated in TFF as\n",
        "[first-class citizens](https://en.wikipedia.org/wiki/First-class_citizen), i.e.,\n",
        "they may appear as parameters and results of functions, and they have types. To\n",
        "reinforce this notion, we will refer to federated data sets as *federated values*, \n",
        "or as *values of federated types*. \n",
        "\n",
        "The important point to understand is that we are modeling the entire collection\n",
        "of data items across all devices (e.g., the entire collection temperature\n",
        "readings from all sensors in a distributed array) as a single federated value.\n",
        "\n",
        "For example, here's how one would define in TFF the type of *federated float*\n",
        "hosted by a group of client devices. A collection of temperature readings that\n",
        "materialize across an array of distributed sensors could be a value of this\n",
        "federated type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "COe0tLPPtTbe"
      },
      "outputs": [],
      "source": [
        "federated_float_on_clients = tff.FederatedType(tf.float32, tff.CLIENTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCAMsF_T8p63"
      },
      "source": [
        "More generally, a federated type in TFF is defined by specifying the type `T` of\n",
        "its *member constituents* - the items of data that reside on individual devices,\n",
        "and the group `G` of devices on which federated values of this type are hosted\n",
        "(plus a third, optional bit of information we'll mention shortly). We refer to\n",
        "the group `G` of devices hosting a federated value as the value's *placement*.\n",
        "Thus, `tff.CLIENTS` is an example of a placement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 79,
          "status": "ok",
          "timestamp": 1549990657525,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "zFVZQwUZ_nbt",
        "outputId": "55b0e482-db97-4c5a-9964-a48e757add6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'float32'"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_float_on_clients.member)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 80,
          "status": "ok",
          "timestamp": 1549990657689,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "eTK00mVb_qi7",
        "outputId": "307a40dc-218c-4a8d-9548-7dc7f872b173"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'CLIENTS'"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_float_on_clients.placement)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q6dp3OHVW_2Q"
      },
      "source": [
        "A federated type with member constituents `T` and placement `G` can be\n",
        "represented compactly as `{T}@G`, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 76,
          "status": "ok",
          "timestamp": 1549990657852,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "eR-9cP219brl",
        "outputId": "e00cd3cf-9121-4d7e-8ca8-d80992952278"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{float32}@CLIENTS'"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(federated_float_on_clients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9kn1logOGtBI"
      },
      "source": [
        "The curly braces `{}` in this concise notation serve as a reminder that the\n",
        "member constituents (items of data on different devices) may differ, as you\n",
        "would expect e.g., of temperature sensor readings, so the clients as a group are\n",
        "jointly hosting a [multi-set](https://en.wikipedia.org/wiki/Multiset) of\n",
        "`T`-typed items that together constitute the federated value.\n",
        "\n",
        "Federated types in TFF come in two flavors: those where the member constituents\n",
        "of a federated value may differ (as just seen above), and those where they are\n",
        "known to be all equal. This is controlled by the third, optional `all_equal`\n",
        "parameter in the `tff.FederatedType` constructor (defaulting to `False`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 76,
          "status": "ok",
          "timestamp": 1549990658036,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "wenF_FnGivCZ",
        "outputId": "72ab258d-ce16-4024-814c-83edec2d7067"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_float_on_clients.all_equal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6wxL6UAkittF"
      },
      "source": [
        "A federated type with a placement `G` in which all of the `T`-typed member\n",
        "constituents are known to be equal can be compactly represented as `T@G` (as\n",
        "opposed to `{T}@G`, that is, with the curly braces dropped to reflect the fact\n",
        "that the multi-set of member constituents consists of a single item)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 116,
          "status": "ok",
          "timestamp": 1549990658283,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "ei1pmBEuLWf-",
        "outputId": "8419a3e5-1818-442c-9756-d3115383583e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'float32@CLIENTS'"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(tff.FederatedType(tf.float32, tff.CLIENTS, all_equal=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pZ2JlbX6H0h5"
      },
      "source": [
        "One example of a federated value of such type that might arise in practical\n",
        "scenarios is a hyperparameter (such as a learning rate, a clipping norm, etc.)\n",
        "that's been broadcasted by a server to a group of devices that participate in\n",
        "federated training.\n",
        "\n",
        "Another example is a set of parameters for a machine learning model \n",
        "pre-trained at the server,  that were then broadcasted to a group of client \n",
        "devices, where they can be personalized for each user.\n",
        "\n",
        "For example, suppose we have a pair of `float32` parameters `a` and `b` for a\n",
        "simple one-dimensional linear regression model. We can construct the\n",
        "(non-federated) type of such models for use in TFF as follows. The angle braces\n",
        "`\u003c\u003e` in the printed type string are a compact TFF notation for named or unnamed\n",
        "tuples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 77,
          "status": "ok",
          "timestamp": 1549990658504,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "noN9mFSN10e6",
        "outputId": "63b10e9b-42be-4f07-c529-0d3cca01dc7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003ca=float32,b=float32\u003e'"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_regression_model = (\n",
        "    tff.NamedTupleType([('a', tf.float32), ('b', tf.float32)]))\n",
        "\n",
        "str(simple_regression_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ytngzr6r10yn"
      },
      "source": [
        "When this model is broadcasted to clients, the type of the\n",
        "resulting federated value can be represented as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 80,
          "status": "ok",
          "timestamp": 1549990658733,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "jZxvM1m9OJZc",
        "outputId": "7c7212a6-e8aa-4827-a0fa-43bc86b537ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003ca=float32,b=float32\u003e@CLIENTS'"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(tff.FederatedType(simple_regression_model, tff.CLIENTS, all_equal=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WfnRcX7rNspF"
      },
      "source": [
        "Per symmetry with *federated float* above, we will refer to such a type as a\n",
        "*federated tuple*. More generally, we'll often use the term *federated XYZ* to\n",
        "refer to a federated value in which member constituents are *XYZ*-like. Thus, we\n",
        "will talk about things like *federated tuples*, *federated sequences*,\n",
        "*federated models*, and so on.\n",
        "\n",
        "Now, coming back to `float32@CLIENTS` - while it appears replicated across\n",
        "multiple devices, it is actually a single `float32`, since all member are the\n",
        "same. In general, you may think of any *all-equal* federated type, i.e., one of\n",
        "the form `T@G`, as isomorphic to a non-federated type `T`, since in both cases,\n",
        "there's actually only a single (albeit potentially replicated) item of type `T`.\n",
        "\n",
        "Given the isomorphism between `T` and `T@G`, you may wonder what purpose, if\n",
        "any, the latter types might serve. Read on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pUXF8WEQLV26"
      },
      "source": [
        "## Placements\n",
        "\n",
        "In the preceding section, we've introduced the concept of *placements* - groups\n",
        "of systems participants that might be jointly hosting a federated value, and\n",
        "we've demonstrated the use of `tff.CLIENTS` as an example specification of a\n",
        "placement.\n",
        "\n",
        "To explain why the notion of a *placement* is so fundamental that we\n",
        "needed to incorporate it into the TFF type system, we need to first say a few\n",
        "words about some of the intended uses of TFF.\n",
        "\n",
        "Although in this tutorial, you will only see TFF code being executed locally in\n",
        "a simulated environment, our goal is for TFF to enable\n",
        "writing code that you can deploy, unmodified, for execution on groups of\n",
        "physical devices in a distributed system, each of which will receive a\n",
        "separate set of instructions to execute locally, depending on the role it plays\n",
        "in the system (an end-user device, a centralized coordinator, an intermediate\n",
        "layer in a multi-tier architecture, etc.) It is important to be able to reason\n",
        "about which subsets of devices execute what code, and where different portions\n",
        "of the data might physically materialize.\n",
        "\n",
        "This is especially important when dealing with, e.g., application data\n",
        "on mobile devices. Since the data is private and can be sensitive, we need the\n",
        "ability to statically verify that this data will never leave the device (and\n",
        "prove facts about how the data is being processed). The placement specifications\n",
        "are one of the mechanisms designed to support this.\n",
        "\n",
        "TFF has been designed as a data-centric programming environment, and as such,\n",
        "unlike some of the existing frameworks that focus on *operations* and where\n",
        "those operations might *run*, TFF focuses on *data*, where that data\n",
        "*materializes*, and how it's being *transformed*. Consequently, placement is\n",
        "modeled as a property of data in TFF, rather than as a property of operations on\n",
        "data. Indeed, as you're about to see in the next section, some of the TFF\n",
        "operations span across locations, and run \"in the network\", so to speak, rather\n",
        "than being executed by a single machine or a group of machines.\n",
        "\n",
        "Representing the type of a certain value as `T@G` or `{T}@G` (as opposed to just\n",
        "`T`) makes data placement decisions explicit, and together with a static\n",
        "analysis of programs written in TFF, it can serve as a foundation for providing\n",
        "formal privacy guarantees for sensitive on-device data.\n",
        "\n",
        "An important thing to note at this point, however, is that while we \n",
        "encourage TFF users to be explicit about *groups* of participating devices \n",
        "that host the data (the placements), the programmer will never deal with the\n",
        "raw data or identities of the *individual* participants.\n",
        "\n",
        "Within the body of TFF code, by design, there's no way to enumerate the\n",
        "devices that constitute the group represented by `tff.CLIENTS`, or to probe for\n",
        "the existence of a specific device in the group. There's no concept of a device\n",
        "or client identity anywhere in the Federated Core API, the underlying set of\n",
        "architectural abstractions, or the core runtime infrastructure we provide to\n",
        "support simulations. All the computation logic you write will be expressed as\n",
        "operations on the entire client group.\n",
        "\n",
        "Placements *are* designed to be a first-class citizen in TFF as well, and can\n",
        "appear as parameters and results of a `placement` type, represented by\n",
        "`tff.PlacementType` in the API. In the future, we plan to provide\n",
        "a variety of operators to transform or combine placements,\n",
        "but this is outside the scope of this tutorial. For now, it suffices to think of\n",
        "`placement` as an opaque primitive built-in type in TFF, similar to how `int`\n",
        "and `bool` are opaque built-in types in Python, with `tff.CLIENTS` being a\n",
        "constant literal of this type, not unlike `1` being a constant literal of type\n",
        "`int`.\n",
        "\n",
        "TFF provides two basic placement literals, `tff.CLIENTS` and `tff.SERVER`, to\n",
        "make it easy to express the rich variety of practical scenarios that are naturally\n",
        "modeled as client-server architectures, with multiple *client* devices (mobile\n",
        "phones, embedded devices, distributed databases, sensors, etc.) orchestrated \n",
        "by a single centralized *server* coordinator. TFF is designed to also support \n",
        "custom placements, multiple client groups, multi-tiered and other, more general\n",
        "distributed architectures, but discussing them is outside the scope of this tutorial.\n",
        "\n",
        "TFF doesn't prescribe what either the `tff.CLIENTS` or the `tff.SERVER` actually\n",
        "represent. In particular, the server may be a single physical device (a member\n",
        "of a singleton group), but it might just as well be a group of replicas in a\n",
        "fault-tolerant cluster running state machine replication - we do not make any\n",
        "special architectural assumptions. Rather, we use the `all_equal` bit mentioned\n",
        "in the preceding section to express the fact that we're generally dealing with\n",
        "only a single item of data at the server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Lmpr7vpA-3A"
      },
      "source": [
        "## Federated computations\n",
        "\n",
        "TFF is designed as a strongly-typed functional programming environment that\n",
        "supports modular development. The basic unit of composition in TFF is a\n",
        "*federated computation* - a section of logic that may accept federated values at\n",
        "input and return federated values at output. Here's how you can define a\n",
        "computation that calculates the average of the temperatures reported by the\n",
        "sensor array from our previous example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "g38EkHwGGEUo"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.FederatedType(tf.float32, tff.CLIENTS))\n",
        "def get_average_temperature(sensor_readings):\n",
        "  return tff.federated_average(sensor_readings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yjRTFxGxY-AL"
      },
      "source": [
        "TFF computations are generally modeled as functions - with or\n",
        "without parameters, but always with well-defined type signatures. Here's how you\n",
        "can print the type signature of the computation `get_average_temperature` just\n",
        "defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 77,
          "status": "ok",
          "timestamp": 1549990659101,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "o7FmRyQACtZU",
        "outputId": "2d5e84b9-b490-4697-f7b2-d510eaf99c00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'({float32}@CLIENTS -\u003e float32@SERVER)'"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(get_average_temperature.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UCJGl2SFAs7S"
      },
      "source": [
        "The type signature tells us that the computation accepts a collection of\n",
        "different sensor readings on client devices, and returns a single average on the\n",
        "server.\n",
        "\n",
        "Functional type signatures are always represented compactly as `(T -\u003e U)` for\n",
        "types `T` and `U` of inputs and outputs, respectively. The type of the\n",
        "formal parameter (such `sensor_readings` in this case) is always specified as\n",
        "the argument to the decorator. You don't need to specify the type of the\n",
        "result - it's determined automatically.\n",
        "\n",
        "Although TFF does offer limited forms of polymorphism, programmers are strongly\n",
        "encouraged to always be explicit about the types of data they work with, as that\n",
        "makes understanding and debugging programs easier. In some cases, expllicitly\n",
        "specifying types is a requirement (e.g., polymorphic computations are currently\n",
        "not directly executable).\n",
        "\n",
        "In order to support development and debugging, TFF allows you to directly invoke\n",
        "computations defined this way as Python functions, as shown below. Where the\n",
        "computation expects a value of a federated type with the `all_equal` bit set to\n",
        "`False`, you can feed it as a plain `list` in Python, and for federated types\n",
        "with the `all_equal` bit set to `True`, you can just directly feed the (single)\n",
        "member constituent. This is also how the results are reported back to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 104,
          "status": "ok",
          "timestamp": 1549990659343,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "HMDW-7U1aREW",
        "outputId": "412f68c1-08af-4db5-c3bc-ddc04f2dea2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "69.533333"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_average_temperature([68.5, 70.3, 69.8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XsTKl4OIBUSH"
      },
      "source": [
        "It is important to understand, however, that although the logic of TFF\n",
        "computations can be expressed as ordinary functions in Python (you just need to\n",
        "decorate them with `tff.federated_computation`), and you can directly invoke\n",
        "them with Python arguments just like any other Python functions in this\n",
        "notebook, behind the scenes, TFF computations are actually *not* Python.\n",
        "\n",
        "What we mean by this is that TFF has an internal language that every section of\n",
        "Python code decorated with `tff.federated_computation` is compiled into.\n",
        "\n",
        "When the Python interpreter encounters a function decorated with\n",
        "`tff.federated_computation`, it traces the statements in this function's body\n",
        "once (at definition time), and then constructs a\n",
        "[serialized representation](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/proto/v0/computation.proto)\n",
        "of the computation's logic for future use - whether for execution, or to be\n",
        "incorporated as a sub-component into another computation.\n",
        "\n",
        "You can think of Python code that defines a federated computation similarly to\n",
        "how you would think of Python code that builds a TensorFlow graph in a non-eager\n",
        "context. The non-eager graph-building code in TensorFlow is Python, but the\n",
        "TensorFlow graph constructed by this code is platform-independent and\n",
        "serializable.\n",
        "\n",
        "Likewise, TFF computations are defined in Python, but immediately compiled into\n",
        "a portable and platform-independent serializable representation under the hood.\n",
        "As a developer, you don't need to concern yourself with the details of this\n",
        "representation, as you will never need to directly work with it, but you should\n",
        "be aware of its existence, the fact that TFF computations are fundamentally\n",
        "non-eager, and cannot capture arbitrary Python state. Python code contained in a\n",
        "TFF computation's body is executed at definition time, when the body of the\n",
        "Python function decorated with `tff.federated_computation` is traced before\n",
        "getting serialized. It's not retraced again at invocation time (except when the\n",
        "function is polymorphic; please refer to the documentation pages for details).\n",
        "\n",
        "You may wonder why we've chosen to introduce a dedicated internal non-Python\n",
        "representation. One reason is that ultimately, TFF computations are\n",
        "intended to be deployable to real physical environments, and hosted on \n",
        "mobile or embedded devices, where Python may not be available.\n",
        "\n",
        "Another reason is that TFF computations express the global behavior of\n",
        "distributed systems, as opposed to Python programs which express the local\n",
        "behavior of individual participants. You can see that in the simple example\n",
        "above, with the special operator `tff.federated_average` that accepts data on\n",
        "client devices, but deposits the results on the server.\n",
        "\n",
        "The operator `tff.federated_average` cannot be easily modeled as an ordinary\n",
        "operator in Python, since it doesn't execute locally - it represents a\n",
        "distributed protocol that coordinates the behavior of multiple system\n",
        "participants. The operator `tff.federated_average` is, in fact, a simple\n",
        "distributed system embedded in the body of the computation. We will refer to\n",
        "such operators as *federated operators*, to distinguish them from ordinary\n",
        "(local) operators in Python.\n",
        "\n",
        "Indeed, federated computations and their constituents *are* best understood as\n",
        "models of distributed systems, and you can think of composing federated\n",
        "computations as composing more complex distributed systems from simpler ones.\n",
        "You can think of the `tff.federated_average` operator as a kind of built-in\n",
        "template federated computation with a type signature `({T}@CLIENTS -\u003e T@SERVER)`\n",
        "(indeed, just like computations you write, this operator also has a complex\n",
        "structure - under the hood we break it down into simpler operators). The TFF\n",
        "type system, and the kinds of operations supported in the TFF's language, thus\n",
        "differ significantly from those in Python, necessitating the use of a dedicated\n",
        "representation.\n",
        "\n",
        "An important restriction to be aware of is that bodies of Python functions\n",
        "decorated with `tff.federated_computation` must consist *only* of federated\n",
        "operators, i.e., they cannot directly contain TensorFlow operations. TensorFlow\n",
        "code must be confined to blocks of code decorated with a `tff.tf_computation`\n",
        "discussed in the following section.\n",
        "\n",
        "The reasons for this separation are technical (it's hard to trick operators such\n",
        "as `tf.add` to work with non-tensors) as well as architectural. The language of\n",
        "federated computations (i.e., the logic constructed from serialized bodies of\n",
        "Python functions decorated with `tff.federated_computation`) is designed to\n",
        "serve as a platform-independent *glue* language. This glue language is currently\n",
        "used to build distributed system from embedded sections of TensorFlow code\n",
        "(confined to `tff.tf_computation` blocks). In the fullness of time, we\n",
        "anticipate the need to embed sections of other, non-TensorFlow logic, such as\n",
        "relational database queries that might represent input pipelines, all connected\n",
        "together using the same glue language (the `tff.federated_computation` blocks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RR4EOrl4errh"
      },
      "source": [
        "## TensorFlow logic\n",
        "\n",
        "TFF is designed for use with TensorFlow. As such, the bulk of the code you will\n",
        "write in TFF is likely to be ordinary (i.e., locally-executing) TensorFlow code.\n",
        "In order to use such code with TFF, as noted above, it just needs to be\n",
        "decorated with `tff.tf_computation`.\n",
        "\n",
        "For example, here's how we could implement a function that takes a number and\n",
        "adds `0.5` to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dpdAqMcygnmr"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tf.float32)\n",
        "def add_half(x):\n",
        "  return tf.add(x, 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c9xofAttjMeD"
      },
      "source": [
        "A computation `add_half` defined this way can be just like any other TFF\n",
        "computation. In particular, it has a TFF type signature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 82,
          "status": "ok",
          "timestamp": 1549990659767,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "93UdxrpgkHgj",
        "outputId": "1012cc28-2881-45fc-d175-f9ae35b3050f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(float32 -\u003e float32)'"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(add_half.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xpiERRtQlBKq"
      },
      "source": [
        "You can also now use it as a building block in other computations . For\n",
        "example, here's how you can use the `tff.federated_map` operator to apply\n",
        "`add_half` pointwise to all member constituents of a federated float on client\n",
        "devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "z08K5UKBlSJP"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(tff.FederatedType(tf.float32, tff.CLIENTS))\n",
        "def add_half_on_clients(x):\n",
        "  return tff.federated_map(add_half, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 78,
          "status": "ok",
          "timestamp": 1549990660120,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "P4wjJgLnlkDW",
        "outputId": "5a4db20e-49c7-4c43-d0d8-e9aeae319aa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'({float32}@CLIENTS -\u003e {float32}@CLIENTS)'"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(add_half_on_clients.type_signature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 145,
          "status": "ok",
          "timestamp": 1549990660419,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "gPsr1oEsl59G",
        "outputId": "a4335a8e-7c3f-4f4b-ba2f-34494dd67e85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1.5, 3.5, 2.5]"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "add_half_on_clients([1.0, 3.0, 2.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yuUOSG-9kK8J"
      },
      "source": [
        "Keep in mind that what we said in the preceding section about TFF computations\n",
        "getting serialized at the definition time remains true for `tff.tf_computation`\n",
        "code as well. The only difference between Python methods decorated with\n",
        "`tff.federated_computation` and those decorated with `tff.tf_computation` is\n",
        "that the latter are serialized as TensorFlow graphs (whereas the former are not\n",
        "allowed to contain TensorFlow code directly embedded in them). Under the hood,\n",
        "each method decorated with `tff.tf_computation` executes against its own\n",
        "instance of an empty `tf.Graph`, even if it is later used as a subcomponent\n",
        "within another `tff.tf_computation` (the examples of which will be shown\n",
        "shortly). You are welcome to use eager TensorFlow, AutoGraph, TensorFlow 2.0\n",
        "constructs, etc., so long as the logic of your computation can get correctly\n",
        "captured as a part of this local `tf.Graph` instance, and correctly serialized\n",
        "into a `tf.GraphDef` (plus metadata) upon exiting the wrapped method's body.\n",
        "Keep in mind that while in the scope of a `tff.tf_computation` function, your\n",
        "code is *not* executing eagerly, even if certain features related to eager\n",
        "execution might be enabled (remember that your code is intended to be deployable\n",
        "to diverse environments, including Android phones, embedded devices, etc.).\n",
        "\n",
        "In particular, `tff.tf_computation` allows you to work with `tf.data.Dataset`s,\n",
        "including abstractly-defined data sets that you can declare as a formal\n",
        "parameter. The support for this is still somewhat limited and evolving, but\n",
        "functional in simple scenarios such as those used in this tutorial.\n",
        "\n",
        "For example, suppose that in our temperature sensor example, each sensor holds\n",
        "not just one temperature reading, but multiple. Here's how you can define a TFF\n",
        "computation in TensorFlow that calculates the average of temperatures in a\n",
        "single local data set using the `tf.data.Dataset.reduce` operator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cw0nen-D0Ks8"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(tff.SequenceType(tf.float32))\n",
        "def get_local_temperature_average(local_temperatures):\n",
        "  sum_and_count = (\n",
        "      local_temperatures.reduce((0.0, 0), lambda x, y: (x[0] + y, x[1] + 1)))\n",
        "  return sum_and_count[0] / tf.to_float(sum_and_count[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0_wjdoS51cey"
      },
      "source": [
        "The type specification `tff.SequenceType(tf.float32)` defines an abstract\n",
        "sequence of float elements in TFF. Sequences can contain either tensors, or\n",
        "complex nested structures (we'll see examples of those later). The concise\n",
        "representation of a sequence of `T`-typed items is `T*`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 116,
          "status": "ok",
          "timestamp": 1549990660906,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "H6Yb5WN_2MFa",
        "outputId": "b37438dd-a55c-4a8f-f5f1-a7671fefd407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'float32*'"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(tff.SequenceType(tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 77,
          "status": "ok",
          "timestamp": 1549990661099,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "wT0V9sJlyqKE",
        "outputId": "066b8c2c-4d6a-471b-bff8-fa23eb689f7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(float32* -\u003e float32)'"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(get_local_temperature_average.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "olZkwEVl2ORH"
      },
      "source": [
        "In the body of a method decorated with `tff.tf_computation`, formal parameters\n",
        "of a TFF sequence type are represented simply as objects that behave like\n",
        "`tf.data.Dataset`. You can easily verify this as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 202,
          "status": "ok",
          "timestamp": 1549990661385,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "_W2tBQxz2wmV",
        "outputId": "3b487ae9-f8c9-4dee-f87f-20718035d06a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@tff.tf_computation(tff.SequenceType(tf.int32))\n",
        "def foo(x):\n",
        "  return x.reduce(np.int32(0), lambda x, y: x + y)\n",
        "\n",
        "foo([1, 2, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k1N5mbpF2tEI"
      },
      "source": [
        "Keep in mind that unlike ordinary `tf.data.Dataset`s, these dataset-like objects\n",
        "are placeholders. They don't contain any elements, since they represent abstract\n",
        "sequence-typed parameters, to be bound to concrete data when used in a concrete\n",
        "context. Support for abstractly-defined placeholer data sets is still somewhat\n",
        "limited at this point, and in the early days of TFF, you may encounter certain\n",
        "restrictions, but we won't need to worry about them in this tutorial (please\n",
        "refer to the documentation pages for details).\n",
        "\n",
        "When locally executing a computation that accepts a sequence in a simulation\n",
        "mode, such as in this tutorial, you can feed the sequence as Python list, as\n",
        "below (as well as in other ways, e.g., as a `tf.data.Dataset` in eager mode, but\n",
        "for now, we'll keep it simple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 199,
          "status": "ok",
          "timestamp": 1549990661669,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "JyNIc79DyuKK",
        "outputId": "9b71ebb7-c725-492b-b1a5-f0027466ee9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "69.533333"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_local_temperature_average([68.5, 70.3, 69.8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Whd5_olh4hxH"
      },
      "source": [
        "Now, let's try again to use our TensorFlow computation in a federated setting.\n",
        "Suppose we have a group of sensors that each have a local sequence of\n",
        "temperature readings. We can compute the global temperature average by averaging\n",
        "the sensors' local averages as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hZIE1kl340at"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(\n",
        "    tff.FederatedType(tff.SequenceType(tf.float32), tff.CLIENTS))\n",
        "def get_global_temperature_average(sensor_readings):\n",
        "  return tff.federated_average(\n",
        "      tff.federated_map(get_local_temperature_average, sensor_readings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RfC3LePY5pUX"
      },
      "source": [
        "Note that this isn't a simple average across all local temperature readings from\n",
        "all clients, as that would require weighing contributions from different clients\n",
        "by the number of readings they locally maintain. We leave it as an exercise for\n",
        "the reader to update the above code; the `tff.federated_average` operator\n",
        "accepts the weight as an optional second argument (expected to be a federated\n",
        "float).\n",
        "\n",
        "Also note that the input to `get_global_temperature_average` now becomes a\n",
        "*federated int sequence*. Federated sequences is how we will typically represent\n",
        "on-device data in federated learning, with sequence elements typically\n",
        "representing data batches (you will see examples of this shortly)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 82,
          "status": "ok",
          "timestamp": 1549990661984,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "SL8-jcqo5krW",
        "outputId": "76bb723c-0357-43cf-8681-41ee8c71c70b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'({float32*}@CLIENTS -\u003e float32@SERVER)'"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(get_global_temperature_average.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RNeQOXA36F4P"
      },
      "source": [
        "Here's how we can locally execute the computation on a sample of data in Python.\n",
        "Notice that the way we supply the input is now as a `list` of `list`s. The outer\n",
        "list iterates over the devices in the group represented by `tff.CLIENTS`, and\n",
        "the inner ones iterate over elements in each device's local sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 437,
          "status": "ok",
          "timestamp": 1549990662523,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "vMzuaF5p6fDJ",
        "outputId": "e46e16ac-3d96-4ae7-9554-349c9c351152"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70.0"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_global_temperature_average([[68.0, 70.0], [71.0], [68.0, 72.0, 70.0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iu5Gd8D6W33s"
      },
      "source": [
        "## Federated averaging\n",
        "\n",
        "Now, let's use what we've learned so far to implement a simple version of\n",
        "federated averaging. For symmetry with\n",
        "[Federated Learning for Image Classification](federated_learning_for_image_classification.md),\n",
        "we are going to use the MNIST example, but since this is intended as a low-level\n",
        "tutorial, we are going to bypass the Keras API and `tff.simulation`, write raw\n",
        "model code, and construct a federated data set from scratch.\n",
        "\n",
        "### Preparing federated data sets\n",
        "\n",
        "For the sake of a demonstration, we're going to simulate a scenario in which we\n",
        "have data from 10 users, and each of the users contributes knowledge how to\n",
        "recognize a different digit. This is about\n",
        "non-[i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)\n",
        "as it gets, and as such, it illustrates well the kind of challenges you may run\n",
        "into working with federated data.\n",
        "\n",
        "First, let's load the standard MNIST data from the TensorFlow website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uThZM4Ds-KDQ"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 81,
          "status": "ok",
          "timestamp": 1549990663054,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "PkJc5rHA2no_",
        "outputId": "00366861-9eea-4aed-f10d-636c4d1b0a9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(x.dtype, x.shape) for x in mnist_train]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mFET4BKJFbkP"
      },
      "source": [
        "The data comes as Numpy arrays, one with images and another with digits, both\n",
        "with the first dimension going over the individual examples. Let's write a\n",
        "helper function that formats it in a way compatible with how we feed federated\n",
        "sequences into TFF computations, i.e., as a list of lists - the outer list\n",
        "ranging over the users (digits), the inner ones ranging over batches of data in\n",
        "each client's sequence. As is customary, we will structure each batch as a pair\n",
        "of tensors named `X` and `Y`, each with the leading batch dimension. While at\n",
        "it, we'll also flatten each image into a 784-element vector and rescale the\n",
        "pixels in it into the `0..1` range, so that we don't have to clutter the model\n",
        "logic with data conversions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XTaTLiq5GNqy"
      },
      "outputs": [],
      "source": [
        "NUM_EXAMPLES_PER_USER = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def get_data_for_digit(source, digit):\n",
        "  output_sequence = []\n",
        "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i + BATCH_SIZE]\n",
        "    output_sequence.append({\n",
        "        'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],\n",
        "                      dtype=np.float32),\n",
        "        'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})\n",
        "  return output_sequence\n",
        "\n",
        "federated_train_data = [get_data_for_digit(mnist_train, d) for d in xrange(10)]\n",
        "\n",
        "federated_test_data = [get_data_for_digit(mnist_test, d) for d in xrange(10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xpNdBimWaMHD"
      },
      "source": [
        "As a quick sanity check, let's look at the `Y` tensor in the last batch of data\n",
        "contributed by the fifth client (the one corresponding to the digit `5`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 104
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 89,
          "status": "ok",
          "timestamp": 1549990665290,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "bTNuL1W4bcuc",
        "outputId": "43d95321-f1ed-4db1-cc78-b1a6f03f1fe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_train_data[5][-1]['y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xgvcwv7Obhat"
      },
      "source": [
        "Just to be sure, let's also look at the image corresponding to the last element of that batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 293
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 290,
          "status": "ok",
          "timestamp": 1549990665679,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "cI4aat1za525",
        "outputId": "ec95479a-25d7-4c24-cb11-2f8a16c592fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003cmatplotlib.image.AxesImage at 0xe8fec90\u003e"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAECCAYAAAD3k8IpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "\u003cmatplotlib.figure.Figure at 0xe8fd210\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28, 28), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RSd6UatXbzw-"
      },
      "source": [
        "### Defining a loss function\n",
        "\n",
        "Now that we have the data, let's define a loss function that we can use for\n",
        "training. First, let's define the type of input as a TFF named tuple. Since the\n",
        "size of data batches may vary, we set the batch dimension to `None` to indicate\n",
        "that the size of this dimension is unknown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 78,
          "status": "ok",
          "timestamp": 1549990665806,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "653xv5NXd4fy",
        "outputId": "8c1dfe25-3a51-4bfe-827c-e52fff92d926"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003cx=float32[?,784],y=int32[?]\u003e'"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_TYPE = tff.NamedTupleType([\n",
        "    ('x', tff.TensorType(tf.float32, [None, 784])),\n",
        "    ('y', tff.TensorType(tf.int32, [None]))])\n",
        "\n",
        "str(BATCH_TYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pb6qPUvyh5A1"
      },
      "source": [
        "You may be wondering why we can't just define an ordinary Python type. Recall\n",
        "the discussion in one of the preceding sections, where we explained that while\n",
        "we can express the logic of TFF computations using Python, under the hood TFF\n",
        "computations *are not* Python. The symbol `BATCH_TYPE` defined above represents\n",
        "an abstract TFF type specification. It is important to distinguish this\n",
        "*abstract* TFF type from concrete Python *representation* types, e.g.,\n",
        "containers such as `dict` or `collections.namedtuple` that may be used to\n",
        "represent the TFF type in the body of a Python function. Unlike Python, TFF has\n",
        "a single abstract type constructor `tff.NamedTupleType` for tuple-like\n",
        "containers, with elements that can be individually named or left unnamed. This\n",
        "type is also used to model formal parameters of computations, as TFF\n",
        "computations can formally only declare one parameter and one result - you will\n",
        "see examples of this shortly.\n",
        "\n",
        "Let's now define the TFF type of model parameters, again as a TFF named tuple of\n",
        "*weights* and *bias*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 111,
          "status": "ok",
          "timestamp": 1549990666010,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "Og7VViafh-30",
        "outputId": "9ee18005-a23e-40fc-ad2a-dc7c9b806898"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003cweights=float32[784,10],bias=float32[10]\u003e'"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_TYPE = tff.NamedTupleType([\n",
        "    ('weights', tff.TensorType(tf.float32, [784, 10])),\n",
        "    ('bias', tff.TensorType(tf.float32, [10]))])\n",
        "\n",
        "str(MODEL_TYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iHhdaWSpfQxo"
      },
      "source": [
        "With those definitions in place, now we can define the loss for a given model, over\n",
        "a single batch. Note how in the body of `batch_loss`, we access named tuple\n",
        "elements using the dot (`X.Y`) notation, as is standard for TFF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4EObiz_Ke0uK"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)\n",
        "  return -tf.reduce_mean(tf.reduce_sum(\n",
        "      tf.one_hot(batch.y, 10) * tf.log(predicted_y), reduction_indices=[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_DVytYGmnfp5"
      },
      "source": [
        "As expected, computation `batch_loss` returns `float32` loss given the model and\n",
        "a single data batch. Note how the `MODEL_TYPE` and `BATCH_TYPE` have been lumped\n",
        "together into a 2-tuple of formal parameters; you can recognize the type of\n",
        "`batch_loss` as `(\u003cMODEL_TYPE,BATCH_TYPE\u003e -\u003e float32)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 108,
          "status": "ok",
          "timestamp": 1549990666344,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "ZGU8HboKndAW",
        "outputId": "94a69f91-564d-4143-d871-6ea7a3998795"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003cweights=float32[784,10],bias=float32[10]\u003e,\u003cx=float32[?,784],y=int32[?]\u003e\u003e -\u003e float32)'"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(batch_loss.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pAnt_UcdnvGa"
      },
      "source": [
        "As a sanity check, let's construct an initial model filled with zeros and\n",
        "compute the loss over the batch of data we visualized above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 258,
          "status": "ok",
          "timestamp": 1549990666691,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "U8Ne8igan3os",
        "outputId": "e7fbcbf4-85b5-486c-b6fd-216ec6e84852"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.3025854"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_model = {\n",
        "    'weights': np.zeros([784, 10], dtype=np.float32),\n",
        "    'bias': np.zeros([10], dtype=np.float32)\n",
        "}\n",
        "\n",
        "sample_batch = federated_train_data[5][-1]\n",
        "\n",
        "batch_loss(initial_model, sample_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ckigEAyDAWFV"
      },
      "source": [
        "Note that we feed the TFF computation with the initial model defined as a\n",
        "`dict`, even though the body of the Python function that defines it consumes\n",
        "model parameters as `model.weight` and `model.bias`. Since, as explained\n",
        "earlier, the logic of a TFF computation is defined in a glue language over\n",
        "abstract TFF types, the choice of a physical Python container in this case\n",
        "doesn't matter. The arguments of the call to `batch_loss` aren't simply passed\n",
        "to the body of that function. Indeed, if you remember the earlier discussion in\n",
        "the section on federated computations, the body of `batch_loss` has already been\n",
        "traced earlier - that is, *before* the invocation, not after. TFF acts as the\n",
        "caller to `batch_loss` at the computation definition time, and as the target of\n",
        "invocation at the time `batch_loss` is invoked. In both roles, TFF serves as the\n",
        "bridge between TFF's abstract type system and Python representation types. At\n",
        "the invocation time, TFF will accept most standard Python container types\n",
        "(`dict`, `list`, `tuple`, `collections.namedtuple`, etc.) as concrete\n",
        "representations of abstract TFF tuples. Also, although as noted above, TFF\n",
        "computations formally only accept a single parameter, you can use the familiar\n",
        "Python call syntax with positional and/or keyword arguments in case where the\n",
        "type of the parameter is a tuple - it works as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eB510nILYbId"
      },
      "source": [
        "### Gradient descent on a single batch\n",
        "\n",
        "Now, let's define a computation that uses this loss function to perform a single\n",
        "step of gradient descent. Note how in defining this function, we use\n",
        "`batch_loss` as a subcomponent. You can always invoke a computation constructed\n",
        "with `tff.tf_computation` inside the body of another computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O4uaVxw3AyYS"
      },
      "outputs": [],
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
        "def batch_train(initial_model, batch, learning_rate):\n",
        "  # Define a group of model variables and set them to `initial_model`.\n",
        "  model_vars = tff.utils.get_variables('v', MODEL_TYPE)\n",
        "  init_model = tff.utils.assign(model_vars, initial_model)\n",
        "\n",
        "  # Perform one step of gradient descent using loss from `batch_loss`.\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "  with tf.control_dependencies([init_model]):\n",
        "    train_model = optimizer.minimize(batch_loss(model_vars, batch))\n",
        "\n",
        "  # Return the model vars after performing this gradient descent step.\n",
        "  with tf.control_dependencies([train_model]):\n",
        "    return tff.utils.identity(model_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 83,
          "status": "ok",
          "timestamp": 1549990667140,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "Y84gQsaohC38",
        "outputId": "74e9ffd5-cbc0-479c-ab10-03f0597ce6dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003cweights=float32[784,10],bias=float32[10]\u003e,\u003cx=float32[?,784],y=int32[?]\u003e,float32\u003e -\u003e \u003cweights=float32[784,10],bias=float32[10]\u003e)'"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(batch_train.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ID8xg9FCUL2A"
      },
      "source": [
        "When you invoke a Python function decorated with `tff.tf_computation` within the\n",
        "body of another such function, the logic of the inner TFF computation that gets\n",
        "created is embedded in the logic of the outer one. You should ideally write your\n",
        "code under the assumption that the inner and outer computations are, for the\n",
        "most part, opaque to each other (thus, it's best to minimize the use of features\n",
        "such as graph introspection or the use of collections). We are actively\n",
        "experimenting with ways to support strong isolation between the inner and outer\n",
        "computations, and if you rely on graph introspection, certain patterns may\n",
        "break. That said, `batch_train` as written above does rely on the ability to\n",
        "trace through the `batch_loss`'s graph in order to compute the gradients.\n",
        "\n",
        "Now, let's apply this function a few times to the initial model to see whether\n",
        "the loss decreases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8edcJTlXUULm"
      },
      "outputs": [],
      "source": [
        "model = initial_model\n",
        "losses = []\n",
        "for _ in xrange(5):\n",
        "  model = batch_train(model, sample_batch, 0.1)\n",
        "  losses.append(batch_loss(model, sample_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 115,
          "status": "ok",
          "timestamp": 1549990668876,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "3n1onojT1zHv",
        "outputId": "1f7bc044-c260-4a99-e66f-1293a055dd14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.19690022, 0.13176313, 0.10113225, 0.082738116, 0.070301391]"
            ]
          },
          "execution_count": 39,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EQk4Ha8PU-3P"
      },
      "source": [
        "### Gradient descent on a sequence of local data\n",
        "\n",
        "Now, since `batch_train` appears to work, let's write a similar training\n",
        "function `local_train` that consumes the entire sequence of all batches from one\n",
        "user instead of just a single batch. The new computation will need to now\n",
        "consume `tff.SequenceType(BATCH_TYPE)` instead of `BATCH_TYPE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EfPD5a6QVNXM"
      },
      "outputs": [],
      "source": [
        "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
        "\n",
        "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
        "def local_train(initial_model, learning_rate, all_batches):\n",
        "\n",
        "  # Mapping function to apply to each batch.\n",
        "  @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "  def batch_fn(model, batch):\n",
        "    return batch_train(model, batch, learning_rate)\n",
        "\n",
        "  return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 106,
          "status": "ok",
          "timestamp": 1549990669227,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "sAhkS5yKUgjC",
        "outputId": "504be76f-3a66-444e-ded8-41a2dad53742"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003cweights=float32[784,10],bias=float32[10]\u003e,float32,\u003cx=float32[?,784],y=int32[?]\u003e*\u003e -\u003e \u003cweights=float32[784,10],bias=float32[10]\u003e)'"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(local_train.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EYT-SiopYBtH"
      },
      "source": [
        "There are quite a few details buried in this short section of code, let's go\n",
        "over them one by one.\n",
        "\n",
        "First, while we could have implemented this logic entirely in TensorFlow,\n",
        "relying on `tf.data.Dataset.reduce` to process the sequence similarly to how\n",
        "we've done it earlier, we've opted this time to express the logic in the glue\n",
        "language, as a `tff.federated_computation`. We've used the federated operator\n",
        "`tff.sequence_reduce` to perform the reduction.\n",
        "\n",
        "The operator `tff.sequence_reduce` is used similarly to\n",
        "`tf.data.Dataset.reduce`. You can think of it as a template operator with a\n",
        "formal parameter 3-tuple that consists of a *sequence* of `T`-typed elements,\n",
        "the initial state of the reduction (we'll refer to it abstractly as *zero*) of\n",
        "some type `U`, and the *reduction operator* of type `(U,T-\u003eU)` that alters the\n",
        "state of the reduction by processing a single element. The result is the final\n",
        "state of the reduction, after processing all elements in a sequential order. In\n",
        "our example, the state of the reduction is the model trained on a prefix of the\n",
        "data, and the elements are data batches.\n",
        "\n",
        "Second, note that we have again used one computation (`batch_train`) as a\n",
        "component within another (`local_train`), but not directly. We can't use it as a\n",
        "reduction operator because it takes an additional parameter - the learning rate.\n",
        "\n",
        "To work around the fact that `batch_train` takes an additional parameter, we\n",
        "define an embedded federated computation `batch_fn` that binds to the\n",
        "`local_train`'s parameter `learning_rate` in its body. It is allowed for a child\n",
        "computation defined this way to capture a formal parameter of its parent as long\n",
        "as the child computation is not invoked outside the body of its parent. You can\n",
        "think of this pattern as an equivalent of `functools.partial` in Python.\n",
        "\n",
        "The practical implication of capturing `learning_rate` this way is, of course,\n",
        "that the same learning rate value is used across all batches.\n",
        "\n",
        "Now, let's try the newly defined local training function on the entire sequence\n",
        "of data from the same user who contributed the sample batch (digit `5`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EnWFLoZGcSby"
      },
      "outputs": [],
      "source": [
        "locally_trained_model = local_train(initial_model, 0.1, federated_train_data[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y0UXUqGk9zoF"
      },
      "source": [
        "Did it work? To answer this question, we need to implement evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a8WDKu6WYy__"
      },
      "source": [
        "### Local evaluation\n",
        "\n",
        "Here's one way to implement local evaluation by adding up the losses across all data\n",
        "batches (we could have just as well computed the average; we'll leave it as an\n",
        "exercise for the reader)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0RiODuc6z7Ln"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval(model, all_batches):\n",
        "  # TODO(b/120157713): Replace with `tff.sequence_average()` once implemented.\n",
        "  return tff.sequence_sum(\n",
        "      tff.sequence_map(\n",
        "          tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),\n",
        "          all_batches))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 81,
          "status": "ok",
          "timestamp": 1549990671721,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "pH2XPEAKa4Dg",
        "outputId": "20dbd2a2-aa4e-4f9d-c578-407fbefd2898"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003cweights=float32[784,10],bias=float32[10]\u003e,\u003cx=float32[?,784],y=int32[?]\u003e*\u003e -\u003e float32)'"
            ]
          },
          "execution_count": 44,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(local_eval.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "efX81HuE-BcO"
      },
      "source": [
        "Again, there are a few new elements illustrated by this code, let's go over them\n",
        "one by one.\n",
        "\n",
        "First, we have used two new federated operators for processing sequences:\n",
        "`tff.sequence_map` that takes a *mapping function* `T-\u003eU` and a *sequence* of\n",
        "`T`, and emits a sequence of `U` obtained by applying the mapping function\n",
        "pointwise, and `tff.sequence_sum` that just adds all the elements. Here, we map\n",
        "each data batch to a loss value, and then add the resulting loss values to\n",
        "compute the total loss.\n",
        "\n",
        "Note that we could have again used `tff.sequence_reduce`, but this wouldn't be\n",
        "the best choice - the reduction process is, by definition, sequential, whereas\n",
        "the mapping and sum can be computed in parallel. When given a choice, it's best\n",
        "to stick with operators that don't constrain implementation choices, so that\n",
        "when our TFF computation is compiled in the future to be deployed to a specific\n",
        "environment, one can take full advantage of all potential opportunities for a\n",
        "faster, more scalable, more resource-efficient execution.\n",
        "\n",
        "Second, note that just as in `local_train`, the component function we need\n",
        "(`batch_loss`) takes more parameters than what the federated operator\n",
        "(`tff.sequence_map`) expects - in this case, the operator wants a function that\n",
        "maps batches to losses, but `batch_loss` also takes a model. Just as we did with\n",
        "the learning rate, we use an embedded computation that captures the\n",
        "`local_eval`'s model in its body in very much the same way we previously\n",
        "captured `learning_rate` in `local_train`'s embedded computation `batch_fn`,\n",
        "thus once again effectively defining a *partial* (a computation with a subset of\n",
        "parameters bound, and the type signature modified to reflect this).\n",
        "\n",
        "The one major difference compared to the previous example is that this time,\n",
        "rather than defining a Python function with `tff.federated_computation` used as\n",
        "a decorator, we've defined the computation inline, by invoking\n",
        "`tff.federated_computation` as an ordinary function (not as a decorator), with a\n",
        "Python lambda and a type signature as arguments. This inline style of defining\n",
        "TFF computations mirrors the use of `lambda` expressions in Python, and can be a\n",
        "good choice for short sections of code like this one.\n",
        "\n",
        "Now, let's see whether our training worked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 434,
          "status": "ok",
          "timestamp": 1549990672253,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "vPw6JSVf5q_x",
        "outputId": "0bab59b7-8e70-4504-80ca-c5f85d6f82a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23.025854"
            ]
          },
          "execution_count": 45,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "local_eval(initial_model, federated_train_data[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 439,
          "status": "ok",
          "timestamp": 1549990672771,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "se4U4lv0C3ao",
        "outputId": "00fe04b0-2932-4fe7-bf0e-d84406b6ac29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.43484691"
            ]
          },
          "execution_count": 46,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "local_eval(locally_trained_model, federated_train_data[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Tvu70cnBsUf"
      },
      "source": [
        "Indeed, the loss decreased. But what happens if we evaluated it on another\n",
        "user's data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 447,
          "status": "ok",
          "timestamp": 1549990673316,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "gjF0NYAj5wls",
        "outputId": "521c5043-3fe6-40c0-b8fb-896eb04dcc1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23.025854"
            ]
          },
          "execution_count": 47,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "local_eval(initial_model, federated_train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 476,
          "status": "ok",
          "timestamp": 1549990673867,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "Sh3POrknC_MK",
        "outputId": "246ec42f-2c01-4ae6-80e7-0d51a0bc49b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "74.500748"
            ]
          },
          "execution_count": 48,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "local_eval(locally_trained_model, federated_train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7WPumnRTBzUs"
      },
      "source": [
        "As expected, things got worse. The model was trained to recognize `5`, and has\n",
        "never seen a `0`. This brings the question - how did the local training impact\n",
        "the quality of the model from the global perspective?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJnL2mQRZKTO"
      },
      "source": [
        "### Federated evaluation\n",
        "\n",
        "This is the point in our journey where we finally circle back to federated types\n",
        "and federated computations - the topic that we started with. Here's a pair of\n",
        "TFF types definitions for the model that originates at the server, and the data\n",
        "that remains on the clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LjGGhpoEBh_6"
      },
      "outputs": [],
      "source": [
        "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)\n",
        "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4gTXV2-jZtE3"
      },
      "source": [
        "With all the definitions introduced so far, expressing federated evaluation in\n",
        "TFF is a one-liner - we distribute the model to clients, let each client invoke\n",
        "local evaluation on its local portion of data, and then average out the loss.\n",
        "Here's one way to write this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2zChEPzEBx4T"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_eval(model, data):\n",
        "  return tff.federated_average(\n",
        "      tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IWcNONNWaE0N"
      },
      "source": [
        "We've already seen examples of `tff.federated_average` and `tff.federated_map`\n",
        "in simpler scenarios, and at the intuitive level, they work as expected, but\n",
        "there's more in this section of code than meets the eye, so let's go over it\n",
        "carefully.\n",
        "\n",
        "First, let's break down the *let each client invoke local evaluation on its\n",
        "local portion of data* part. As you may recall from the preceding sections,\n",
        "`local_eval` has a type signature of the form `(\u003cMODEL_TYPE, LOCAL_DATA_TYPE\u003e -\u003e\n",
        "float32)`.\n",
        "\n",
        "The federated operator `tff.federated_map` is a template that accepts as a\n",
        "parameter a 2-tuple that consists of the *mapping function* of some type `T-\u003eU`\n",
        "and a federated value of type `{T}@CLIENTS` (i.e., with member constituents of\n",
        "the same type as the parameter of the mapping function), and returns a result of\n",
        "type `{U}@CLIENTS`.\n",
        "\n",
        "Since we're feeding `local_eval` as a mapping function to apply on a per-client\n",
        "basis, the second argument should be a federated of type `\u003cMODEL_TYPE,\n",
        "LOCAL_DATA_TYPE\u003e@CLIENTS`, i.e., in the nomenclature of the preceding sections,\n",
        "it should be a federated tuple. Each client should hold a full set of arguments\n",
        "for `local_eval` as a member consituent. Instead, we're feeding it a 2-element\n",
        "Python `list`. What's happening here?\n",
        "\n",
        "Indeed, this is an example of an *implicit type cast* in TFF, similar to\n",
        "implicit type casts you may have encountered elsewhere, e.g., when you feed an\n",
        "`int` to a function that accepts a `float`. Implicit casting is used scarcily at\n",
        "this point, but we plan to make it more pervasive in TFF as a way to minimize\n",
        "boilerplate.\n",
        "\n",
        "The implicit cast that's applied in this case is the equivalence between\n",
        "federated tuples of the form `\u003cX,Y\u003e@Z`, and tuples of federated values\n",
        "`\u003cX@Z,Y@Z\u003e`. While formally, these two are different type signatures, looking at\n",
        "it from the programmers's perspective, each device in `Z` holds two units of\n",
        "data `X` and `Y`. What happens here is not unlike `zip` in Python, and indeed,\n",
        "we offer an operator `tff.federated_zip` that allows you to perform such\n",
        "conversions explicity. When the `tff.federated_map` encounters a tuple as a\n",
        "second argument, it simply invokes `tff.federated_zip` for you.\n",
        "\n",
        "Given the above, you should now be able to recognize the expression\n",
        "`tff.federated_broadcast(model)` as representing a value of TFF type\n",
        "`{MODEL_TYPE}@CLIENTS`, and `data` as a value of TFF type\n",
        "`{LOCAL_DATA_TYPE}@CLIENTS` (or simply `CLIENT_DATA_TYPE`), the two getting\n",
        "filtered together through an implicit `tff.federated_zip` to form the second\n",
        "argument to `tff.federated_map`.\n",
        "\n",
        "The operator `tff.federated_broadcast`, as you'd expect, simply transfers data\n",
        "from the server to the clients.\n",
        "\n",
        "Now, let's see how our local training affected the average loss in the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3606,
          "status": "ok",
          "timestamp": 1549990677885,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "TXgnzTDvCGQ4",
        "outputId": "e9f6bfcf-9f40-444e-abda-6af78f688a5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23.025852"
            ]
          },
          "execution_count": 51,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_eval(initial_model, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3516,
          "status": "ok",
          "timestamp": 1549990681486,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "sR2b0la_CWQr",
        "outputId": "95014f1d-756f-4a90-b609-d231bd2afc04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "54.432625"
            ]
          },
          "execution_count": 52,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_eval(locally_trained_model, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LQi2rGX_fK7i"
      },
      "source": [
        "Indeed, as expected, the loss has increased. In order to improve the model for\n",
        "all users, we'll need to train in on everyone's data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vkw9f59qfS7o"
      },
      "source": [
        "### Federated training\n",
        "\n",
        "The simplest way to implement federated training is to locally train, and then\n",
        "average the models. This uses the same building blocks and patters we've already\n",
        "discussed, as you can see below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mBOC4uoG6dd-"
      },
      "outputs": [],
      "source": [
        "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)\n",
        "\n",
        "@tff.federated_computation(\n",
        "    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_train(model, learning_rate, data):\n",
        "  return tff.federated_average(\n",
        "      tff.federated_map(\n",
        "          local_train,\n",
        "          [tff.federated_broadcast(model),\n",
        "           tff.federated_broadcast(learning_rate),\n",
        "           data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z2vACMsQjzO1"
      },
      "source": [
        "In reality, rather than averaging the models, we prefer to average model deltas,\n",
        "for a number of reasons, e.g., such as the ability to clip their norms, for\n",
        "compression, etc. This is a trivial change in TFF, as you'll just need to\n",
        "subtract the model from the argument to `tff.federated_average`, and then add it\n",
        "back to the result. We'll leave this change as an exercise for the user.\n",
        "\n",
        "Let's see whether the training works by running a few rounds of training and\n",
        "comparing the average loss before and after."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NLx-3rLs9jGY"
      },
      "outputs": [],
      "source": [
        "#@test {\"timeout\": 300}\n",
        "model = initial_model\n",
        "learning_rate = 0.1\n",
        "losses = []\n",
        "for _ in xrange(5):\n",
        "  model = federated_train(model, learning_rate, federated_train_data)\n",
        "  learning_rate = learning_rate * 0.9\n",
        "  losses.append(federated_eval(model, federated_train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 298,
          "status": "ok",
          "timestamp": 1549990808702,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "vPLD8UHSI-eP",
        "outputId": "d626834d-e5df-4a01-883b-3f45225ab5af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[21.605524, 20.365679, 19.274801, 18.31111, 17.457254]"
            ]
          },
          "execution_count": 55,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0VjSLQzlUIp"
      },
      "source": [
        "For completeness, let's now also run on the test data to confirm that our model\n",
        "generalizes well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3296,
          "status": "ok",
          "timestamp": 1549990812120,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "ZaZT45yFMOaM",
        "outputId": "6abbf64e-82a3-4b8b-f409-068ffe1d0bc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.795593"
            ]
          },
          "execution_count": 56,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_eval(initial_model, federated_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3388,
          "status": "ok",
          "timestamp": 1549990815583,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "A9Uk7NpFM1Ho",
        "outputId": "f182b375-bf93-4abf-ca29-85ada2d44ffe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17.278767"
            ]
          },
          "execution_count": 57,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_eval(model, federated_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pxlHHwLGlgFB"
      },
      "source": [
        "Of course, our simplified example doesn't capture everything you'd need to do in\n",
        "a more realistic scenario - for example, we haven't computed metrics other than\n",
        "loss, and we only ran it for a few rounds. Those topics will be covered in\n",
        "follow-up tutorials."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Custom Federated Algorithms with the Federated Core API",
      "provenance": [
        {
          "file_id": "1FuV5nQFsa54XJSahUG0RwZpPGQzdTz_D",
          "timestamp": 1547078723514
        }
      ],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
