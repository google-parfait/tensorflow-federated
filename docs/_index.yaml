book_path: /federated/_book.yaml
project_path: /federated/_project.yaml
description: <!--no description-->
landing_page:
  custom_css_path: /site-assets/css/style.css
  rows:
  - heading: "TensorFlow Federated: Machine Learning on Decentralized Data"
    items:
    - classname: devsite-landing-row-50
      list:
      - description: >
          <!-- Please keep the content of this file in sync with README.md -->
          <p>TensorFlow Federated (TFF) is an open-source framework for machine learning and other
          computations on decentralized data. TFF has been developed to facilitate open research and
          experimentation with
          <a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" class="external">Federated Learning (FL)</a>,
          an approach to machine learning where a shared global model is trained across many
          participating clients that keep their training data locally. For example, FL has been used
          to train
          <a href="https://arxiv.org/abs/1811.03604" class="external">prediction models for mobile keyboards</a>
          without uploading sensitive typing data to servers.</p>
          <p>TFF enables developers to simulate the included federated learning algorithms on their
          models and data, as well as to experiment with novel algorithms. The building blocks
          provided by TFF can also be used to implement non-learning computations, such as aggregated
          analytics over decentralized data. TFFâ€™s interfaces are organized in two layers:</p>
      - heading: Federated Learning (FL) API
        description: >
          This layer offers a set of high-level interfaces that allow developers to apply the
          included implementations of federated training and evaluation to their existing
          TensorFlow models.
        path: /federated/federated_learning
        icon:
          icon_name: chevron_right
          foreground: theme
          background: grey
      - heading: Federated Core (FC) API
        description: >
          At the core of the system is a set of lower-level interfaces for concisely expressing
          novel federated algorithms by combining TensorFlow with distributed communication
          operators within a strongly-typed functional programming environment. This layer also
          serves as the foundation upon which we've built Federated Learning.
        path: /federated/federated_core
        icon:
          icon_name: chevron_right
          foreground: theme
          background: grey
      - description: >
          TFF enables developers to declaratively express federated computations, so they could be
          deployed to diverse runtime environments. Included with TFF is a single-machine
          simulation runtime for experiments. Please visit the
          <a href="/federated/tutorials/federated_learning_for_image_classification">tutorials</a>
          and try it out yourself!
      code_block: |
        <pre class = "prettyprint">
        from six.moves import range
        import tensorflow as tf
        import tensorflow_federated as tff
        from tensorflow_federated.python.examples import mnist
        tf.compat.v1.enable_v2_behavior()

        # Load simulation data.
        source, _ = tff.simulation.datasets.emnist.load_data()
        def client_data(n):
          dataset = source.create_tf_dataset_for_client(source.client_ids[n])
          return mnist.keras_dataset_from_emnist(dataset).repeat(10).batch(20)

        # Pick a subset of client devices to participate in training.
        train_data = [client_data(n) for n in range(3)]

        # Grab a single batch of data so that TFF knows what data looks like.
        sample_batch = tf.contrib.framework.nest.map_structure(
            lambda x: x.numpy(), iter(train_data[0]).next())

        # Wrap a Keras model for use with TFF.
        def model_fn():
          return tff.learning.from_compiled_keras_model(
              mnist.create_simple_keras_model(), sample_batch)

        # Simulate a few rounds of training with the selected client devices.
        trainer = tff.learning.build_federated_averaging_process(model_fn)
        state = trainer.initialize()
        for _ in range(5):
          state, metrics = trainer.next(state, train_data)
          print (metrics.loss)
        </pre>

  - classname: devsite-landing-row-cards
    items:
    - heading: "TensorFlow Federated (TFF): Machine Learning on Decentralized Data"
      youtube_id: 1YbPmkChcbo
      buttons:
      - label: Watch the video
        path: https://www.youtube.com/watch?v=1YbPmkChcbo
    - heading: "Introducing TensorFlow Federated"
      image_path: /resources/images/tf-logo-card-16x9.png
      path: https://medium.com/tensorflow/introducing-tensorflow-federated-a4147aa20041
      buttons:
      - label: "Read on TensorFlow blog"
        path: https://medium.com/tensorflow/introducing-tensorflow-federated-a4147aa20041
    - heading: "Federated Learning: Collaborative Machine Learning without Centralized Training Data"
      image_path: /resources/images/google-research-card-16x9.png
      path: https://ai.googleblog.com/2017/04/federated-learning-collaborative.html
      buttons:
      - label: "Read on Google AI blog"
        path: https://ai.googleblog.com/2017/04/federated-learning-collaborative.html

  - classname: devsite-landing-row-cards
    items:
    - heading: "Making every phone smarter with Federated Learning"
      youtube_id: gbRJPa9d-VU
      buttons:
      - label: Watch the video
        path: https://www.youtube.com/watch?v=gbRJPa9d-VU
    - heading: "TF Federated on GitHub"
      image_path: /resources/images/github-card-16x9.png
      path: https://github.com/tensorflow/federated
      buttons:
      - label: "View on GitHub"
        path: https://github.com/tensorflow/federated
